{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8210b19",
   "metadata": {},
   "source": [
    "## A.I. Assignment 5\n",
    "\n",
    "## Learning Goals\n",
    "\n",
    "By the end of this lab, you should be able to:\n",
    "* Get more familiar with tensors in pytorch \n",
    "* Create a simple multilayer perceptron model with pytorch\n",
    "* Visualise the parameters\n",
    "\n",
    "\n",
    "### Task\n",
    "\n",
    "Build a fully connected feed forward network that adds two bits. Determine the a propper achitecture for this network (what database you use for this problem? how many layers? how many neurons on each layer? what is the activation function? what is the loss function? etc)\n",
    "\n",
    "Create at least 3 such networks and compare their performance (how accurate they are?, how farst they are trained to get at 1 accuracy?)\n",
    "\n",
    "Display for the best one the weights for each layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e3614e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ee7e7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_in = torch.tensor([[0,0], [0,1], [1,0], [1,1]], dtype=torch.float)\n",
    "data_target = torch.tensor([[0,0], [0,1], [1,0], [1,1]], dtype=torch.float)\n",
    "\n",
    "# Model 1: Simple 2-layer network\n",
    "model1 = nn.Sequential(OrderedDict([\n",
    "    ('hidden', nn.Linear(2, 2)),\n",
    "    ('activation1', nn.ReLU()),\n",
    "    ('output', nn.Linear(2, 2)),\n",
    "    ('activation2', nn.Sigmoid())\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "665ae958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (hidden): Linear(in_features=2, out_features=2, bias=True)\n",
      "  (activation1): ReLU()\n",
      "  (output): Linear(in_features=2, out_features=2, bias=True)\n",
      "  (activation2): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e26f0d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = nn.Sequential(OrderedDict([\n",
    "    ('hidden1', nn.Linear(2, 4)),\n",
    "    ('activation1', nn.ReLU()),\n",
    "    ('hidden2', nn.Linear(4, 2)),\n",
    "    ('activation2', nn.ReLU()),\n",
    "    ('output', nn.Linear(2, 2)),\n",
    "    ('activation3', nn.Sigmoid())\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4fb16bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "# data_target = torch.tensor( ...\n",
    "print(data_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "69d920ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function (criterion)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Assuming we're working with model3, the best performing model based on the previous steps\n",
    "# Define the optimizer\n",
    "optimizer = torch.optim.Adam(model2.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cde91f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.701137900352478\n",
      "Epoch 101, Loss: 0.3849238157272339\n",
      "Epoch 201, Loss: 0.2252417951822281\n",
      "Epoch 301, Loss: 0.19352859258651733\n",
      "Epoch 401, Loss: 0.18490494787693024\n",
      "Epoch 501, Loss: 0.18117627501487732\n",
      "Epoch 601, Loss: 0.17919717729091644\n",
      "Epoch 701, Loss: 0.17775171995162964\n",
      "Epoch 801, Loss: 0.17711353302001953\n",
      "Epoch 901, Loss: 0.17626681923866272\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'data_in' and 'data_target' are defined as inputs and expected outputs\n",
    "\n",
    "epochs = 1000  # Number of iterations to train the model\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Zero the gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs = model2(data_in)\n",
    "    \n",
    "    # Compute loss\n",
    "    loss = criterion(outputs, data_target)\n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update model parameters\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Optionally print the loss every 100 epochs\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dff3ec1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions vs Actual:\n",
      "[0. 0.] => [0. 1.] (Actual: [0. 0.])\n",
      "[0. 1.] => [0. 1.] (Actual: [0. 1.])\n",
      "[1. 0.] => [1. 0.] (Actual: [1. 0.])\n",
      "[1. 1.] => [1. 1.] (Actual: [1. 1.])\n"
     ]
    }
   ],
   "source": [
    "print(\"Predictions vs Actual:\")\n",
    "for i in range(len(data_in)):\n",
    "    print(f\"{data_in[i].numpy()} => {predictions[i].detach().numpy()} (Actual: {data_target[i].numpy()})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c1a7518b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden1.weight: tensor([[-2.7785,  1.0573],\n",
      "        [-0.1753, -0.3988],\n",
      "        [-0.5143,  0.1024],\n",
      "        [ 2.8393, -1.2131]])\n",
      "hidden1.bias: tensor([ 2.2913, -0.1572, -0.3129,  1.2131])\n",
      "hidden2.weight: tensor([[ 2.1426, -0.2790,  0.0901, -0.9777],\n",
      "        [ 1.5590, -0.3196, -0.0526, -2.7997]])\n",
      "hidden2.bias: tensor([ 1.1339, -0.1764])\n",
      "output.weight: tensor([[-2.6318, -0.6545],\n",
      "        [-1.3929,  3.8019]])\n",
      "output.bias: tensor([ 4.7205e+00, -1.3757e-03])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model2.named_parameters():\n",
    "    print(f\"{name}: {param.data}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdf09ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bea66c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29c65a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
